{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for processing IMERG Rainfall data in Blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to process the rainfall data on Blob for each cyclone since Favio. It extracts the daily on-land rainfall values from -2 days to +5 days to landfall in a 250km radius around the landfall location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "from azure.storage.blob import ContainerClient\n",
    "import numpy as np\n",
    "import warnings\n",
    "from shapely.geometry import Point\n",
    "from rasterio.features import geometry_mask\n",
    "from scipy.interpolate import interp1d\n",
    "from pyproj import CRS\n",
    "\n",
    "load_dotenv()\n",
    "ADMS = [\"Sofala\", \"Inhambane\", \"Nampula\", \"Zambezia\"]\n",
    "AA_DATA_DIR = Path(os.getenv(\"AA_DATA_DIR\"))\n",
    "AA_DATA_DIR_NEW = Path(os.getenv(\"AA_DATA_DIR_NEW\"))\n",
    "\n",
    "DEV_BLOB_SAS = os.getenv(\"DSCI_AZ_SAS_DEV\")\n",
    "DEV_BLOB_NAME = \"imb0chd0dev\"\n",
    "DEV_BLOB_URL = f\"https://{DEV_BLOB_NAME}.blob.core.windows.net/\"\n",
    "DEV_BLOB_PROJ_URL = DEV_BLOB_URL + \"projects\" + \"?\" + DEV_BLOB_SAS\n",
    "GLOBAL_CONTAINER_NAME = \"global\"\n",
    "DEV_BLOB_GLB_URL = DEV_BLOB_URL + GLOBAL_CONTAINER_NAME + \"?\" + DEV_BLOB_SAS\n",
    "\n",
    "dev_glb_container_client = ContainerClient.from_container_url(DEV_BLOB_GLB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1_path = (\n",
    "    AA_DATA_DIR\n",
    "    / \"public\"\n",
    "    / \"raw\"\n",
    "    / \"moz\"\n",
    "    / \"cod_ab\"\n",
    "    / \"moz_admbnda_adm1_ine_20190607.shp\"\n",
    ")\n",
    "\n",
    "gdf_adm1 = gpd.read_file(adm1_path)\n",
    "gdf_sel = gdf_adm1[gdf_adm1.ADM1_PT.isin(ADMS)]\n",
    "ibtracs_path = (\n",
    "    Path(AA_DATA_DIR)\n",
    "    / \"public\"\n",
    "    / \"raw\"\n",
    "    / \"glb\"\n",
    "    / \"ibtracs\"\n",
    "    / \"IBTrACS.SI.list.v04r01.points/IBTrACS.SI.list.v04r01.points.shp\"\n",
    ")\n",
    "adm2_path = (\n",
    "    AA_DATA_DIR\n",
    "    / \"public\"\n",
    "    / \"raw\"\n",
    "    / \"moz\"\n",
    "    / \"cod_ab\"\n",
    "    / \"moz_admbnda_adm2_ine_20190607.shp\"\n",
    ")\n",
    "\n",
    "gdf_adm2 = gpd.read_file(adm2_path)\n",
    "gdf_sel_adm2 = gdf_adm2[gdf_adm2.ADM1_PT.isin(ADMS)]\n",
    "\n",
    "minx, miny, maxx, maxy = gdf_sel.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blob_names = existing_files = [\n",
    "#    x.name for x in dev_glb_container_client.list_blobs(name_starts_with=\"imerg/v6/\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_ibtracs = gpd.read_file(ibtracs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_adm1_sel_buff = gdf_adm1[gdf_adm1.ADM1_PT.isin(ADMS)].buffer(250 / 111)\n",
    "# also making sure to take one time step before landfall since some storms even off shore can cause a lot of rain\n",
    "gdf_ibtracs_time = gdf_ibtracs[gdf_ibtracs[\"ISO_TIME\"] >= \"2003-03-11\"]\n",
    "# which cyclones made landfall or came close by around 50km to land\n",
    "landfall_cyclones = gpd.sjoin(\n",
    "    gdf_ibtracs_time, gdf_sel, how=\"inner\", predicate=\"intersects\"\n",
    ")[\"NAME\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAVIO', 'JOKWE', 'IZILDA', 'DANDO', 'IRINA', 'HARUNA', 'DELIWE',\n",
       "       'GUITO', 'HELLEN', 'CHEDZA', 'DINEO', 'DESMOND', 'IDAI', 'KENNETH',\n",
       "       'CHALANE', 'ELOISE', 'GUAMBE', 'ANA', 'GOMBE', 'JASMINE', 'FREDDY',\n",
       "       'FILIPO'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landfall_cyclones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 100, 150, 200, 250, 300, 350, 400, 450, 500]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = []\n",
    "landfall_locs = []\n",
    "# dates = pd.date_range(start=\"2003-03-11\", periods=len(das), freq=\"D\")\n",
    "radii = list(range(50, 501, 50))\n",
    "radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAVIO\n",
      "JOKWE\n",
      "IZILDA\n",
      "DANDO\n",
      "IRINA\n",
      "HARUNA\n",
      "DELIWE\n",
      "GUITO\n",
      "HELLEN\n",
      "CHEDZA\n",
      "DINEO\n",
      "DESMOND\n",
      "IDAI\n",
      "KENNETH\n",
      "CHALANE\n",
      "ELOISE\n",
      "GUAMBE\n",
      "ANA\n",
      "GOMBE\n",
      "JASMINE\n",
      "FREDDY\n",
      "FILIPO\n"
     ]
    }
   ],
   "source": [
    "for cyc in landfall_cyclones:\n",
    "    cyc_df = gdf_ibtracs_time[gdf_ibtracs_time[\"NAME\"] == cyc]\n",
    "    # Convert ISO_TIME to datetime and set as index\n",
    "    cyc_df[\"ISO_TIME\"] = pd.to_datetime(cyc_df[\"ISO_TIME\"])\n",
    "    cyc_df.set_index(\"ISO_TIME\", inplace=True)\n",
    "\n",
    "    # Resample the DataFrame to the desired frequency\n",
    "    cyc_df = cyc_df.resample(\"30T\").asfreq()\n",
    "\n",
    "    # Interpolate numerical columns and forward fill text columns\n",
    "    for column in cyc_df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(cyc_df[column]):\n",
    "            non_nan = cyc_df[column].dropna()\n",
    "            if len(non_nan) > 1:\n",
    "                interp_func = interp1d(\n",
    "                    non_nan.index.astype(np.int64),\n",
    "                    non_nan.values,\n",
    "                    kind=\"linear\",\n",
    "                    fill_value=\"extrapolate\",\n",
    "                )\n",
    "                cyc_df[column] = interp_func(cyc_df.index.astype(np.int64))\n",
    "        else:\n",
    "            cyc_df[column] = cyc_df[column].ffill()\n",
    "\n",
    "    # Reset index\n",
    "    cyc_df.reset_index(inplace=True)\n",
    "    cyc_df[\"geometry\"] = cyc_df.apply(\n",
    "        lambda row: Point(row[\"LON\"], row[\"LAT\"]), axis=1\n",
    "    )\n",
    "    cyc_df = gpd.GeoDataFrame(cyc_df, geometry=\"geometry\")\n",
    "    cyc_df[\"date\"] = pd.to_datetime(cyc_df[\"ISO_TIME\"]).dt.date\n",
    "    cyc_sjoin = gpd.sjoin(cyc_df, gdf_adm1, how=\"left\", predicate=\"within\")\n",
    "    cyc_df[\"ADM1_PT\"] = cyc_sjoin[\"ADM1_PT\"]\n",
    "    cyc_df[\"actual_within_land\"] = cyc_sjoin[\"index_right\"].notna()\n",
    "    cyc_df[\"point_location\"] = np.where(\n",
    "        cyc_df[\"actual_within_land\"], \"Within\", \"Outside\"\n",
    "    )\n",
    "\n",
    "    first_landfall = (\n",
    "        cyc_df[cyc_df[\"actual_within_land\"]].index[0]\n",
    "        if not cyc_df[cyc_df[\"actual_within_land\"]].empty\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    if first_landfall is not None:\n",
    "        entry_times = []\n",
    "        lookback = 4\n",
    "        for i in range(lookback, len(cyc_df)):\n",
    "            if (\n",
    "                not cyc_df[\"actual_within_land\"].iloc[i - 1]\n",
    "                and cyc_df[\"actual_within_land\"].iloc[i]\n",
    "            ):\n",
    "                direction_east_to_west = True\n",
    "                for j in range(i - lookback, i - 1):\n",
    "                    if cyc_df[\"LON\"].iloc[j] < cyc_df[\"LON\"].iloc[j + 1]:\n",
    "                        direction_east_to_west = False\n",
    "                        break\n",
    "                if direction_east_to_west:\n",
    "                    entry_times.append(cyc_df[\"ISO_TIME\"].iloc[i])\n",
    "\n",
    "        entry_times = pd.to_datetime(entry_times)\n",
    "        entry_dates = pd.Series(entry_times).dt.date.unique().tolist()\n",
    "\n",
    "        if len(entry_dates) == 1:\n",
    "            entry_times = [entry_times[0]]\n",
    "\n",
    "        cyc_df.loc[cyc_df[\"ISO_TIME\"].isin(entry_times), \"point_location\"] = (\n",
    "            \"Landfall\"\n",
    "        )\n",
    "        landfall_locs.append(cyc_df[cyc_df[\"point_location\"] == \"Landfall\"])\n",
    "        print(cyc)\n",
    "        for landfall in entry_times:\n",
    "            landfall_time = pd.to_datetime(\n",
    "                cyc_df[cyc_df[\"point_location\"] == \"Landfall\"][\n",
    "                    \"ISO_TIME\"\n",
    "                ].values[0]\n",
    "            )\n",
    "            lf_dt = cyc_df[cyc_df[\"point_location\"] == \"Landfall\"]\n",
    "\n",
    "            # Iterate over each date and radius\n",
    "            storm_df_list = []\n",
    "            for time_step in range(-2, 6):\n",
    "                date = landfall + pd.Timedelta(days=time_step)\n",
    "                target_date = date.normalize()\n",
    "                blob_name = f\"imerg/v6/imerg-daily-late-{target_date.strftime('%Y-%m-%d')}.tif\"\n",
    "                cog_url = f\"https://{DEV_BLOB_NAME}.blob.core.windows.net/global/{blob_name}?{DEV_BLOB_SAS}\"\n",
    "\n",
    "                try:\n",
    "                    da_in = rxr.open_rasterio(cog_url, masked=True)\n",
    "                    da_in = da_in.persist()\n",
    "                    if da_in.rio.crs is None:\n",
    "                        da_in.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "                except Exception as e:\n",
    "                    da_in = None\n",
    "\n",
    "                if da_in is not None:\n",
    "                    for radius in radii:\n",
    "                        # Create a GeoDataFrame for the landfall point with the buffer\n",
    "                        gdf_lf = gpd.GeoDataFrame(\n",
    "                            {\n",
    "                                \"geometry\": [\n",
    "                                    Point(\n",
    "                                        lf_dt[\"LON\"].values[0],\n",
    "                                        lf_dt[\"LAT\"].values[0],\n",
    "                                    )\n",
    "                                ]\n",
    "                            },\n",
    "                            crs=CRS(\"EPSG:4326\"),\n",
    "                        )\n",
    "                        gdf_lf[\"geometry\"] = gdf_lf.buffer(\n",
    "                            radius / 110.574\n",
    "                        )  # Buffer radius\n",
    "                        gdf_lf = gpd.overlay(\n",
    "                            gdf_lf, gdf_sel, how=\"intersection\"\n",
    "                        )\n",
    "                        if gdf_lf.shape[0] > 0:\n",
    "                            polygon_union = gdf_lf.unary_union\n",
    "                            mask = geometry_mask(\n",
    "                                [polygon_union],\n",
    "                                transform=da_in.rio.transform(),\n",
    "                                invert=True,\n",
    "                                out_shape=da_in.rio.shape,\n",
    "                            )\n",
    "                            masked_da = da_in.where(mask)\n",
    "                            values = masked_da.values[\n",
    "                                ~np.isnan(masked_da.values)\n",
    "                            ]\n",
    "                            median_value = (\n",
    "                                np.median(values)\n",
    "                                if values.size > 0\n",
    "                                else np.nan\n",
    "                            )\n",
    "                        else:\n",
    "                            median_value = np.nan\n",
    "\n",
    "                        # Append results to storm_df_list\n",
    "                        storm_df_list.append(\n",
    "                            {\n",
    "                                \"storm\": cyc,\n",
    "                                \"date\": date,\n",
    "                                \"time_step\": time_step,\n",
    "                                \"radius\": radius,\n",
    "                                \"median_precip\": median_value,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            # Create DataFrame from storm_df_list\n",
    "            storm_df = pd.DataFrame(storm_df_list)\n",
    "            combined_df.append(storm_df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "rain_df = pd.concat(combined_df, ignore_index=True)\n",
    "landfall_df = pd.concat(landfall_locs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm</th>\n",
       "      <th>date</th>\n",
       "      <th>time_step</th>\n",
       "      <th>radius</th>\n",
       "      <th>median_precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-23 15:00:00</td>\n",
       "      <td>-2</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-23 15:00:00</td>\n",
       "      <td>-2</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-23 15:00:00</td>\n",
       "      <td>-2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-23 15:00:00</td>\n",
       "      <td>-2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.005736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-23 15:00:00</td>\n",
       "      <td>-2</td>\n",
       "      <td>250</td>\n",
       "      <td>0.001962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-30 15:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>5.049721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-30 15:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>350</td>\n",
       "      <td>5.077960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-30 15:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>4.585343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-30 15:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>450</td>\n",
       "      <td>4.242187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>2019-04-30 15:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>4.269989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        storm                date  time_step  radius  median_precip\n",
       "960   KENNETH 2019-04-23 15:00:00         -2      50            NaN\n",
       "961   KENNETH 2019-04-23 15:00:00         -2     100            NaN\n",
       "962   KENNETH 2019-04-23 15:00:00         -2     150       0.000912\n",
       "963   KENNETH 2019-04-23 15:00:00         -2     200       0.005736\n",
       "964   KENNETH 2019-04-23 15:00:00         -2     250       0.001962\n",
       "...       ...                 ...        ...     ...            ...\n",
       "1035  KENNETH 2019-04-30 15:00:00          5     300       5.049721\n",
       "1036  KENNETH 2019-04-30 15:00:00          5     350       5.077960\n",
       "1037  KENNETH 2019-04-30 15:00:00          5     400       4.585343\n",
       "1038  KENNETH 2019-04-30 15:00:00          5     450       4.242187\n",
       "1039  KENNETH 2019-04-30 15:00:00          5     500       4.269989\n",
       "\n",
       "[80 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_df[rain_df[\"storm\"] == \"KENNETH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df.to_csv(\n",
    "    AA_DATA_DIR\n",
    "    / \"public\"\n",
    "    / \"processed\"\n",
    "    / \"moz\"\n",
    "    / \"daily_imerg_cyclone_landfall_fixed.csv\"\n",
    ")\n",
    "landfall_df.to_csv(\n",
    "    AA_DATA_DIR\n",
    "    / \"public\"\n",
    "    / \"processed\"\n",
    "    / \"moz\"\n",
    "    / \"landfall_time_location_fixed.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
