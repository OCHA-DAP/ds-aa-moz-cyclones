{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import glob\n",
    "from shapely.geometry import Point\n",
    "from datetime import timedelta\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "AA_DATA_DIR = os.getenv(\"AA_DATA_DIR\")\n",
    "save_dir = Path(AA_DATA_DIR) / \"public\" / \"exploration\" / \"moz\" / \"ecmwf_hindcast\"\n",
    "ADMS = [\"Sofala\", \"Inhambane\", \"Nampula\", \"Zambezia\"]\n",
    "adm1_path = (\n",
    "    Path(AA_DATA_DIR)\n",
    "    / \"public\"\n",
    "    / \"raw\"\n",
    "    / \"moz\"\n",
    "    / \"cod_ab\"\n",
    "    / \"moz_admbnda_adm1_ine_20190607.shp\"\n",
    ")\n",
    "gdf_adm1 = gpd.read_file(adm1_path)\n",
    "gdf_sel = gdf_adm1[gdf_adm1.ADM1_PT.isin(ADMS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cyclone(wind_speed):\n",
    "    if wind_speed > 115:\n",
    "        return \"Very Intense Tropical Cyclone\"\n",
    "    elif wind_speed >= 90:\n",
    "        return \"Intense Tropical Cyclone\"\n",
    "    elif wind_speed >= 64:\n",
    "        return \"Tropical Cyclone\"\n",
    "    elif wind_speed >= 48:\n",
    "        return \"Severe Tropical Storm\"\n",
    "    elif wind_speed >= 34:\n",
    "        return \"Moderate Tropical Storm\"\n",
    "    elif wind_speed >= 28:\n",
    "        return \"Tropical Depression\"\n",
    "    else:\n",
    "        return \"Tropical Disturbance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\favio_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\jokwe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\izilda_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\dando_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\irina_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\haruna_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\deliwe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\guito_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\hellen_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\chedza_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\dineo_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\desmond_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\idai_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\kenneth_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\chalane_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\eloise_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\guambe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\ana_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\gombe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\jasmine_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\freddy_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\filipo_all.csv\n"
     ]
    }
   ],
   "source": [
    "moz_cyclones = [\n",
    "    Path(f).stem.replace(\"_all\", \"\").upper()\n",
    "    for f in glob.glob(str(Path(save_dir) / \"csv\" / \"*_all.csv\"))\n",
    "]\n",
    "cyclone_speed = []\n",
    "for cyclone_file_path in glob.glob(str(save_dir / \"csv/*_all.csv\")):\n",
    "    cyclone_name = Path(cyclone_file_path).stem.split(\"_\")[0]\n",
    "    print(f\"Processing file: {cyclone_file_path}\")\n",
    "    cyclone_file = pd.read_csv(cyclone_file_path)\n",
    "    cyclone_file[\"time\"] = pd.to_datetime(cyclone_file[\"time\"])\n",
    "\n",
    "    cyclone_df = (\n",
    "        cyclone_file[[\"time\", \"speed\", \"lat\", \"lon\", \"lead_time\", \"forecast_time\"]]\n",
    "        .groupby([\"time\", \"forecast_time\"])\n",
    "        .median()\n",
    "        .reset_index()\n",
    "    )\n",
    "    cyclone_df[\"lat\"] = cyclone_df[\"lat\"].apply(lambda x: -x if x > 0 else x)\n",
    "\n",
    "    cyclone_df[\"speed_knots\"] = cyclone_df[\"speed\"] * 1.94384\n",
    "    cyclone_df[\"storm_category\"] = cyclone_df[\"speed_knots\"].apply(categorize_cyclone)\n",
    "    cyc_ls = []\n",
    "    for ts, ts_df in cyclone_df.groupby(\"forecast_time\"):\n",
    "        lt_0_df = gpd.GeoDataFrame(\n",
    "            ts_df, geometry=gpd.points_from_xy(ts_df.lon, ts_df.lat), crs=\"EPSG:4326\"\n",
    "        )\n",
    "        cyc_sjoin = gpd.sjoin(lt_0_df, gdf_sel, how=\"left\", predicate=\"intersects\")\n",
    "        lt_0_df[\"within_land\"] = cyc_sjoin[\"index_right\"].notna()\n",
    "        lt_0_df[\"point_location\"] = np.where(\n",
    "            lt_0_df[\"within_land\"], \"Within\", \"Outside\"\n",
    "        )\n",
    "\n",
    "        first_landfall = (\n",
    "            lt_0_df[lt_0_df[\"within_land\"]].index[0]\n",
    "            if not lt_0_df[lt_0_df[\"within_land\"]].empty\n",
    "            else None\n",
    "        )\n",
    "        if first_landfall is None:\n",
    "            continue\n",
    "        lt_0_df.loc[lt_0_df.index == first_landfall, \"point_location\"] = \"Landfall\"\n",
    "        landfall_time = pd.to_datetime(\n",
    "            lt_0_df[lt_0_df[\"point_location\"] == \"Landfall\"][\"time\"].values[0]\n",
    "        )\n",
    "        lt_0_df[\"time_to_landfall\"] = (\n",
    "            landfall_time - pd.to_datetime(lt_0_df[\"forecast_time\"])\n",
    "        ).dt.total_seconds() / 3600\n",
    "        lt_0_df[\"time_from_landfall\"] = (\n",
    "            lt_0_df[\"lead_time\"] - lt_0_df[\"time_to_landfall\"]\n",
    "        )\n",
    "        # lt_0_df = lt_0_df[(lt_0_df[\"time_to_landfall\"] <= 12)]\n",
    "        cyc_df = lt_0_df  # [(lt_0_df[\"point_location\"] != \"Outside\") | ((lt_0_df[\"time_from_landfall\"] >= -12) & (lt_0_df[\"time_from_landfall\"] <= 12))]\n",
    "        cyc_ls.append(cyc_df)\n",
    "    if len(cyc_ls) > 0:\n",
    "        cyc_df = pd.concat(cyc_ls)\n",
    "        cyc_df[\"storm\"] = cyclone_name.upper()\n",
    "        cyclone_speed.append(cyc_df)\n",
    "\n",
    "cyclone_out = pd.concat(cyclone_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\favio_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\jokwe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\izilda_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\dando_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\irina_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\haruna_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\deliwe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\guito_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\hellen_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\chedza_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\dineo_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\desmond_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\idai_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\kenneth_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\chalane_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\eloise_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\guambe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\ana_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\gombe_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\jasmine_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\freddy_all.csv\n",
      "Processing file: G:\\Shared drives\\Predictive Analytics\\CERF Anticipatory Action\\General - All AA projects\\Data\\public\\exploration\\moz\\ecmwf_hindcast\\csv\\filipo_all.csv\n"
     ]
    }
   ],
   "source": [
    "cyclone_speed = []\n",
    "for cyclone_file_path in glob.glob(str(save_dir / \"csv/*_all.csv\")):\n",
    "    cyclone_name = Path(cyclone_file_path).stem.split(\"_\")[0]\n",
    "    print(f\"Processing file: {cyclone_file_path}\")\n",
    "    cyclone_file = pd.read_csv(cyclone_file_path)\n",
    "    cyclone_file[\"time\"] = pd.to_datetime(cyclone_file[\"time\"])\n",
    "\n",
    "    cyclone_df = (\n",
    "        cyclone_file[[\"time\", \"speed\", \"lat\", \"lon\", \"lead_time\", \"forecast_time\"]]\n",
    "        .groupby([\"time\", \"forecast_time\"])\n",
    "        .median()\n",
    "        .reset_index()\n",
    "    )\n",
    "    cyclone_df[\"lat\"] = cyclone_df[\"lat\"].apply(lambda x: -x if x > 0 else x)\n",
    "\n",
    "    cyclone_df[\"speed_knots\"] = cyclone_df[\"speed\"] * 1.94384\n",
    "    cyclone_df[\"storm_category\"] = cyclone_df[\"speed_knots\"].apply(categorize_cyclone)\n",
    "    cyc_ls = []\n",
    "    lt_0_df = gpd.GeoDataFrame(\n",
    "        cyclone_df,\n",
    "        geometry=gpd.points_from_xy(cyclone_df.lon, cyclone_df.lat),\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    cyc_sjoin = gpd.sjoin(lt_0_df, gdf_sel, how=\"left\", predicate=\"intersects\")\n",
    "    lt_0_df[\"within_land\"] = cyc_sjoin[\"index_right\"].notna()\n",
    "    lt_0_df[\"point_location\"] = np.where(lt_0_df[\"within_land\"], \"Within\", \"Outside\")\n",
    "\n",
    "    first_landfall = (\n",
    "        lt_0_df[lt_0_df[\"within_land\"]].index[0]\n",
    "        if not lt_0_df[lt_0_df[\"within_land\"]].empty\n",
    "        else None\n",
    "    )\n",
    "    if first_landfall is None:\n",
    "        continue\n",
    "    lt_0_df.loc[lt_0_df.index == first_landfall, \"point_location\"] = \"Landfall\"\n",
    "    landfall_time = pd.to_datetime(\n",
    "        lt_0_df[lt_0_df[\"point_location\"] == \"Landfall\"][\"time\"].values[0]\n",
    "    )\n",
    "    lt_0_df[\"time_to_landfall\"] = (\n",
    "        landfall_time - pd.to_datetime(lt_0_df[\"forecast_time\"])\n",
    "    ).dt.total_seconds() / 3600\n",
    "    lt_0_df[\"time_from_landfall\"] = lt_0_df[\"lead_time\"] - lt_0_df[\"time_to_landfall\"]\n",
    "    # lt_0_df = lt_0_df[(lt_0_df[\"time_to_landfall\"] <= 12)]\n",
    "    cyc_df = lt_0_df  # [(lt_0_df[\"point_location\"] != \"Outside\") | ((lt_0_df[\"time_from_landfall\"] >= -12) & (lt_0_df[\"time_from_landfall\"] <= 12))]\n",
    "    cyc_ls.append(cyc_df)\n",
    "    if len(cyc_ls) > 0:\n",
    "        cyc_df = pd.concat(cyc_ls)\n",
    "        cyc_df[\"storm\"] = cyclone_name.upper()\n",
    "        cyclone_speed.append(cyc_df)\n",
    "\n",
    "cyclone_out = pd.concat(cyclone_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_out.to_csv(\n",
    "    \"C:/Users/pauni/Desktop/Work/OCHA/Mozambique/cyclone_landfall_speed.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
