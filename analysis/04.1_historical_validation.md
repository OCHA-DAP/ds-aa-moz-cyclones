---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.16.3
  kernelspec:
    display_name: .venv
    language: python
    name: python3
---

# Comparing ECMWF and La ReUnion forecasts against La ReUnion Best Track data


This notebook looks at the two sources and compares the performance and review which cyclones would be activated historically.

```python
%load_ext jupyter_black
%load_ext autoreload
%autoreload 2
```

```python
from pathlib import Path
from datetime import datetime
import os
import numpy as np


import geopandas as gpd
import pandas as pd
from shapely.geometry import Point
from src.datasources import codab, helpers, rsmc
from src import constants
```

```python
save_dir = rsmc.DATA_DIR / "public" / "exploration" / "moz" / "ecmwf_hindcast"
```

```python
# Complete list of storms
all_storms = [
    "FAVIO",
    "JOKWE",
    "IZILDA",
    "DANDO",
    "IRINA",
    "HARUNA",
    "DELIWE",
    "GUITO",
    "HELLEN",
    "CHEDZA",
    "DINEO",
    "DESMOND",
    "IDAI",
    "KENNETH",
    "CHALANE",
    "ELOISE",
    "GUAMBE",
    "ANA",
    "GOMBE",
    "JASMINE",
    "FREDDY",
    "FILIPO",
]
ADM2_48 = [
    "Angoche",
    "Maganja Da Costa",
    "Machanga",
    "Govuro",
]
ADM2_64 = [
    "Mogincual",
    "Namacurra",
    "Dondo",
    "Cidade Da Beira",
    "Buzi",
    "Vilankulo",
]
```

```python
adm = codab.load_codab(aoi_only=True)
adm.plot()
```

```python
adm2_path = (
    rsmc.DATA_DIR
    / "public"
    / "raw"
    / "moz"
    / "cod_ab"
    / "moz_admbnda_adm2_ine_20190607.shp"
)

adm2 = gpd.read_file(adm2_path)
adm2_sel = adm2[adm2["ADM2_PT"].isin(constants.ADMS2)]
adm2_sel.plot()
```

```python
# loading all actual cyclone tracks
cyclone_tracks = pd.read_csv(
    rsmc.DATA_DIR
    / "private"
    / "raw"
    / "moz"
    / "rsmc"
    / "data_cyclone_SWIO_19851986_to_20222023.csv"
)
```

```python
cyclone_tracks["Lat"] = cyclone_tracks["Lat"].apply(
    lambda x: -x if x > 0 else x
)
```

```python
cyclone_tracks["geometry"] = cyclone_tracks.apply(
    lambda row: Point(row["Lon"], row["Lat"]), axis=1
)
cyclone_tracks_gdf = gpd.GeoDataFrame(
    cyclone_tracks, geometry="geometry", crs="EPSG:4326"
)
```

```python
cyclone_tracks_sel = gpd.sjoin(
    cyclone_tracks_gdf, adm, how="inner", predicate="intersects"
)
```

```python
cyclone_tracks_sel.plot()
```

```python
cyclone_tracks_sel["Name"].unique()
```

```python
df = rsmc.load_historical_forecast_distances()
```

```python
ibtracs_path = rsmc.DATA_DIR / "public" / "raw" / "glb" / "ibtracs"
points_path = Path(
    ibtracs_path
    / "IBTrACS.SI.list.v04r01.points/IBTrACS.SI.list.v04r01.points.shp"
)
gdf_points = gpd.read_file(points_path)
```

```python
gdf_points["Date"] = [
    datetime.strptime(dt, "%Y-%m-%d %H:%M:%S").date()
    for dt in gdf_points["ISO_TIME"]
]

gdf_points["REU_USA_WIND"] = gdf_points["REU_WIND"].fillna(
    gdf_points["USA_WIND"] * 0.88
)
gdf_points["ISO_TIME"] = pd.to_datetime(gdf_points["ISO_TIME"])
```

```python
df = df[df["name"].isin(all_storms)]
```

La ReUnion forecasts vs Best Track Data

```python
df.columns
```

Adding which cyclones would be triggered using ECMWF

```python
ecmwf_cyclone_data = helpers.load_all_cyclone_csvs(save_dir)
ecmwf_cyclone_data["lat"] = ecmwf_cyclone_data["lat"].apply(
    lambda x: -x if x > 0 else x
)
interpolated_ecmwf_data = helpers.interpolate_cyclone_tracks(
    ecmwf_cyclone_data
)
```

```python
ecmwf_cyclone_gdf = gpd.GeoDataFrame(
    ecmwf_cyclone_data,
    geometry=gpd.points_from_xy(
        ecmwf_cyclone_data.lon, ecmwf_cyclone_data.lat
    ),
    crs="EPSG:4326",  # Assuming WGS84
)
ecmwf_cyclones_on_land = gpd.sjoin(
    ecmwf_cyclone_gdf, adm2_sel, how="inner", predicate="intersects"
)
ecmwf_cyclones_on_land_obs = gpd.sjoin(
    ecmwf_cyclone_gdf, adm, how="inner", predicate="intersects"
)
```

```python
# readiness
readiness_storms = ecmwf_cyclones_on_land[
    ((ecmwf_cyclones_on_land["lead_time"] > 72))
    & (ecmwf_cyclones_on_land["speed"] >= (48 * 0.514444))
]["cyclone_name"].unique()
readiness_storms
```

```python
# action
action_storms = ecmwf_cyclones_on_land[
    ((ecmwf_cyclones_on_land["lead_time"] >= 6))
    & (ecmwf_cyclones_on_land["lead_time"] <= 72)
    & (ecmwf_cyclones_on_land["speed"] >= (48 * 0.514444))
]["cyclone_name"].unique()
action_storms
```

```python
# observational
obs_ws_storms = ecmwf_cyclones_on_land_obs[
    ((ecmwf_cyclones_on_land_obs["lead_time"] == 0))
    & (ecmwf_cyclones_on_land_obs["speed"] >= (48 * 0.514444))
]["cyclone_name"].unique()
obs_ws_storms
```

```python
interpolated_ecmwf_data[
    (interpolated_ecmwf_data["cyclone_name"] == "FREDDY")
    & (interpolated_ecmwf_data["speed"] >= 48 * 0.514444)
]
```

```python
# Lists of storm events
df = pd.DataFrame(
    {
        "storm": all_storms,
        "Total Affected": [
            162770,
            220013,
            7103,
            40042,
            4958,
            None,
            None,
            None,
            None,
            None,
            750102,
            None,
            1628167,
            400094,
            73254,
            481901,
            None,
            185429,
            736015,
            None,
            1143569,
            50781,
        ],
        "CERF Allocations": [
            1070014,
            548913,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            2000095,
            None,
            14018121,
            9964907,
            None,
            None,
            None,
            None,
            4018682,
            None,
            9995213,
            None,
        ],
    }
)
df["Readiness"] = [storm in readiness_storms for storm in all_storms]
df["Action"] = [storm in action_storms for storm in all_storms]
df["Observational Wind Speed"] = [
    storm in obs_ws_storms for storm in all_storms
]
df = df[
    [
        "storm",
        "Readiness",
        "Action",
        "Observational Wind Speed",
        "Total Affected",
        "CERF Allocations",
    ]
]

# Sort the DataFrame by 'Total Affected' in descending order
# Round values in 'Total Affected' and 'CERF Allocations' columns
df_sorted = df.sort_values(by="Total Affected", ascending=False)


# Define functions for highlighting and coloring bars
def highlight_true(val):
    color = "red" if val else ""
    return f"background-color: {color}"


def color_bar_affected(val):
    if isinstance(val, (int, float)) and not pd.isna(val):
        return f'background: linear-gradient(90deg, orange {val/df_sorted["Total Affected"].max()*100}%, transparent {val/df_sorted["Total Affected"].max()*100}%);'
    return ""


def color_bar_cerf(val):
    if isinstance(val, (int, float)) and not pd.isna(val):
        return f'background: linear-gradient(90deg, green {val/df_sorted["CERF Allocations"].max()*100}%, transparent {val/df_sorted["CERF Allocations"].max()*100}%);'
    return ""


# Apply styling
styled_df = (
    df_sorted.style.map(
        highlight_true,
        subset=[
            "Readiness",
            "Action",
            # "Observational Rainfall",
            "Observational Wind Speed",
        ],
    )
    .map(color_bar_affected, subset=["Total Affected"])
    .map(color_bar_cerf, subset=["CERF Allocations"])
    .format(
        {
            "Total Affected": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
            "CERF Allocations": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
        }
    )
    .set_table_styles(
        {"": [{"selector": "table", "props": "background-color: white;"}]}
    )
)

# Display the styled DataFrame
styled_df
```

Adding which cyclones would be triggered using La ReUnion

```python
df_rsmc_dist = rsmc.load_historical_forecast_distances()
```

```python
df_rsmc = pd.read_parquet(
    rsmc.DATA_DIR
    / "private"
    / "processed"
    / "moz"
    / "rsmc"
    / "rsmc_forecasts_interp_distances_withradius.parquet"
)
```

```python
# adding buffer
df_rsmc["radius_max_wind_km"] = (
    df_rsmc["radius_max_wind_nm"].astype(float) * 1.852
)
```

```python
mf_lr_gdf = gpd.GeoDataFrame(
    df_rsmc,
    geometry=gpd.points_from_xy(df_rsmc.longitude, df_rsmc.latitude),
    crs="EPSG:4326",  # Assuming WGS84
)
mf_lr_gdf.plot()
```

```python
mf_lr_gdf_buffer = mf_lr_gdf.copy()
mf_lr_gdf_buffer["radius_max_wind_km"] = (
    mf_lr_gdf_buffer["radius_max_wind_km"].fillna(0.001).replace(0, 0.001)
)
mf_lr_gdf_buffer["geometry"] = mf_lr_gdf_buffer.geometry.buffer(
    mf_lr_gdf_buffer["radius_max_wind_km"] / 110.574
)
mf_lr_gdf_buffer.plot()
```

```python
mf_lr_on_land_adm1 = gpd.sjoin(
    mf_lr_gdf, adm, how="inner", predicate="intersects"
)
mf_lr_on_land_adm2 = gpd.sjoin(
    mf_lr_gdf, adm2_sel, how="inner", predicate="intersects"
)
mf_lr_on_land_adm2_buffer = gpd.sjoin(
    mf_lr_gdf_buffer, adm2_sel, how="inner", predicate="intersects"
)
```

```python
mf_lr_on_land_adm1["name"].unique()  # cyclones that made it to land
```

```python
# readiness
buffer = True
if buffer:
    mf_lr_on_land_adm2_df = mf_lr_on_land_adm2_buffer
else:
    mf_lr_on_land_adm2_df = mf_lr_on_land_adm2
```

```python
# readiness
# Get storms that meet the thresholds
readiness_storms = mf_lr_on_land_adm2_df[
    (mf_lr_on_land_adm2_df["lt_hour"] > 72)
    & (
        (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
        | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
    )
]["name"].unique()
readiness_storms
```

```python
# action
action_storms = mf_lr_on_land_adm2_df[
    ((mf_lr_on_land_adm2_df["lt_hour"] >= 6))
    & (mf_lr_on_land_adm2_df["lt_hour"] <= 72)
    & (
        (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
        | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
    )
]["name"].unique()
action_storms
```

```python
# observational
obs_ws_storms = mf_lr_on_land_adm1[
    ((mf_lr_on_land_adm1["lt_hour"] == 0))
    & (mf_lr_on_land_adm1["max_wind_kt"] >= (48))
]["name"].unique()
obs_ws_storms
```

```python
rain_df = pd.read_csv(
    rsmc.DATA_DIR
    / "public"
    / "processed"
    / "moz"
    / "daily_imerg_cyclone_landfall_fixed.csv"
)
imerg_data = rain_df[(rain_df["radius"] == 250)]
imerg_df = imerg_data[
    imerg_data["time_step"].isin([-1, 0, 1])
].copy()  # Create a copy to avoid warnings
# Ensure 'date' is in datetime format
imerg_df["date"] = pd.to_datetime(imerg_df["date"], format="%d/%m/%Y %H:%M")
# Create month_year column
imerg_df["year_month"] = imerg_df["date"].dt.to_period("M")
imerg_sum_df = (
    imerg_df.groupby(["storm", "year_month"])["median_precip"]
    .sum()
    .reset_index()
)

obs_rain_storms = imerg_sum_df[imerg_sum_df["median_precip"] >= 55][
    "storm"
].unique()
# rename IDAI 1 to IDAI
obs_rain_storms[obs_rain_storms == "IDAI 1"] = "IDAI"
obs_rain_storms
```

```python
# Lists of storm events
df["Readiness"] = [storm in readiness_storms for storm in all_storms]
df["Action"] = [storm in action_storms for storm in all_storms]
df["Observational Wind Speed"] = [
    storm in obs_ws_storms for storm in all_storms
]
df["Observational Rainfall"] = [
    storm in obs_rain_storms for storm in all_storms
]
df = df[
    [
        "storm",
        "Readiness",
        "Action",
        "Observational Wind Speed",
        "Observational Rainfall",
        "Total Affected",
        "CERF Allocations",
    ]
]

# Sort the DataFrame by 'Total Affected' in descending order
# Round values in 'Total Affected' and 'CERF Allocations' columns
df_sorted = df.sort_values(by="Total Affected", ascending=False)


# Define functions for highlighting and coloring bars
def highlight_true(val):
    color = "red" if val else ""
    return f"background-color: {color}"


def color_bar_affected(val):
    if isinstance(val, (int, float)) and not pd.isna(val):
        return f'background: linear-gradient(90deg, orange {val/df_sorted["Total Affected"].max()*100}%, transparent {val/df_sorted["Total Affected"].max()*100}%);'
    return ""


def color_bar_cerf(val):
    if isinstance(val, (int, float)) and not pd.isna(val):
        return f'background: linear-gradient(90deg, green {val/df_sorted["CERF Allocations"].max()*100}%, transparent {val/df_sorted["CERF Allocations"].max()*100}%);'
    return ""


# Apply styling
styled_df = (
    df_sorted.style.map(
        highlight_true,
        subset=[
            "Readiness",
            "Action",
            "Observational Wind Speed",
            "Observational Rainfall",
        ],
    )
    .map(color_bar_affected, subset=["Total Affected"])
    .map(color_bar_cerf, subset=["CERF Allocations"])
    .format(
        {
            "Total Affected": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
            "CERF Allocations": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
        }
    )
    .set_table_styles(
        {"": [{"selector": "table", "props": "background-color: white;"}]}
    )
)

# Display the styled DataFrame
styled_df
```

```python
# checking which months and years each trigger would have been met
# readiness
readiness_trigger_years = (
    mf_lr_on_land_adm2_df[
        ((mf_lr_on_land_adm2_df["lt_hour"] > 72))
        & (
            (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
            | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
        )
    ]["valid_time"]
    .dt.tz_localize(None)  # Remove timezone information
    .dt.to_period("M")
    .unique()
)
readiness_trigger_years
```

```python
# action
action_trigger_years = (
    mf_lr_on_land_adm2_df[
        ((mf_lr_on_land_adm2_df["lt_hour"] >= 6))
        & (mf_lr_on_land_adm2_df["lt_hour"] <= 72)
        & (
            (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
            | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
        )
    ]["valid_time"]
    .dt.tz_localize(None)  # Remove timezone information
    .dt.to_period("M")
    .unique()
)
action_trigger_years
```

```python
# observational
obs_ws_trigger_years = (
    mf_lr_on_land_adm1[
        ((mf_lr_on_land_adm1["lt_hour"] == 0))
        & (mf_lr_on_land_adm1["max_wind_kt"] >= (48))
    ]["valid_time"]
    .dt.tz_localize(None)  # Remove timezone information
    .dt.to_period("M")
    .unique()
)
obs_ws_trigger_years
```

```python
obs_rain_trigger_years = imerg_sum_df[imerg_sum_df["median_precip"] >= 55][
    "year_month"
].unique()
obs_rain_trigger_years
```

```python
min_year_windspeed = "2010-10"
min_year_rainfall = "2003-03"
max_year_rainfall = ""
```

```python
historical_activations = pd.DataFrame(
    {"year_month": pd.period_range(start="2000-01", end="2024-06", freq="M")}
)
historical_activations["readiness"] = historical_activations[
    "year_month"
].isin(readiness_trigger_years)
historical_activations["action"] = historical_activations["year_month"].isin(
    action_trigger_years
)
historical_activations["observational_windspeed"] = historical_activations[
    "year_month"
].isin(obs_ws_trigger_years)
historical_activations["observational_rainfall"] = historical_activations[
    "year_month"
].isin(obs_rain_trigger_years)
# Apply the date constraints
historical_activations.loc[
    historical_activations["year_month"]
    < pd.Period(min_year_windspeed, freq="M"),
    ["readiness", "action", "observational_windspeed"],
] = np.nan
historical_activations.loc[
    historical_activations["year_month"]
    < pd.Period(min_year_rainfall, freq="M"),
    "observational_rainfall",
] = np.nan

historical_activations
```

```python
historical_activations.to_csv(
    rsmc.DATA_DIR / "public/processed/moz/historical_activations.csv",
    index=False,
)
```
