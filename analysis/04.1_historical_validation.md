---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: .venv
    language: python
    name: python3
---

# Comparing ECMWF and La ReUnion forecasts against La ReUnion Best Track data


This notebook looks at the two sources and compares the performance and review which cyclones would be activated historically.

```python
%load_ext jupyter_black
%load_ext autoreload
%autoreload 2
```

```python
from pathlib import Path
from datetime import datetime
import os

import geopandas as gpd
import pandas as pd
import numpy as np
from shapely.geometry import Point
from src.datasources import codab, helpers, rsmc
from src.constants import *
from src.utils import *
```

```python
save_dir = rsmc.DATA_DIR / "public" / "exploration" / "moz" / "ecmwf_hindcast"
```

```python
# Complete list of storms
storm_cerf_file = pd.read_csv(
    rsmc.DATA_DIR / "public" / "raw" / "moz" / "storms_cerf_data.csv"
)
```

```python
all_storms = storm_cerf_file["storm"]
```

```python
adm = codab.load_codab(aoi_only=True)
adm.plot()
```

```python
adm2_path = (
    rsmc.DATA_DIR
    / "public"
    / "raw"
    / "moz"
    / "cod_ab"
    / "moz_admbnda_adm2_ine_20190607.shp"
)

adm2 = gpd.read_file(adm2_path)
adm2_sel = adm2[adm2["ADM2_PT"].isin(ADMS2)]
adm2_sel.plot()
```

```python
# loading all actual cyclone tracks
cyclone_tracks = pd.read_csv(
    rsmc.DATA_DIR
    / "private"
    / "raw"
    / "moz"
    / "rsmc"
    / "data_cyclone_SWIO_19851986_to_20222023.csv"
)
```

```python
cyclone_tracks["Lat"] = cyclone_tracks["Lat"].apply(
    lambda x: -x if x > 0 else x
)
```

```python
cyclone_tracks["geometry"] = cyclone_tracks.apply(
    lambda row: Point(row["Lon"], row["Lat"]), axis=1
)
cyclone_tracks_gdf = gpd.GeoDataFrame(
    cyclone_tracks, geometry="geometry", crs="EPSG:4326"
)
```

```python
cyclone_tracks_sel = gpd.sjoin(
    cyclone_tracks_gdf, adm, how="inner", predicate="intersects"
)
```

```python
cyclone_tracks_sel.plot()
```

```python
cyclone_tracks_sel["Name"].unique()
```

```python
df = rsmc.load_historical_forecast_distances()
```

```python
ibtracs_path = rsmc.DATA_DIR / "public" / "raw" / "glb" / "ibtracs"
points_path = Path(
    ibtracs_path
    / "IBTrACS.SI.list.v04r01.points/IBTrACS.SI.list.v04r01.points.shp"
)
gdf_points = gpd.read_file(points_path)
```

```python
gdf_points["Date"] = [
    datetime.strptime(dt, "%Y-%m-%d %H:%M:%S").date()
    for dt in gdf_points["ISO_TIME"]
]

gdf_points["REU_USA_WIND"] = gdf_points["REU_WIND"].fillna(
    gdf_points["USA_WIND"] * MIN1_TO_MIN10
)
gdf_points["ISO_TIME"] = pd.to_datetime(gdf_points["ISO_TIME"])
```

```python
df = df[df["name"].isin(all_storms)]
```

La ReUnion forecasts vs Best Track Data

```python
df.columns
```

Adding which cyclones would be triggered using ECMWF

```python
ecmwf_cyclone_data = helpers.load_all_cyclone_csvs(save_dir)
ecmwf_cyclone_data["lat"] = ecmwf_cyclone_data["lat"].apply(
    lambda x: -x if x > 0 else x
)
interpolated_ecmwf_data = helpers.interpolate_cyclone_tracks(
    ecmwf_cyclone_data
)
```

```python
ecmwf_cyclone_gdf = gpd.GeoDataFrame(
    ecmwf_cyclone_data,
    geometry=gpd.points_from_xy(
        ecmwf_cyclone_data.lon, ecmwf_cyclone_data.lat
    ),
    crs="EPSG:4326",  # Assuming WGS84
)
ecmwf_cyclones_on_land = gpd.sjoin(
    ecmwf_cyclone_gdf, adm2_sel, how="inner", predicate="intersects"
)
ecmwf_cyclones_on_land_obs = gpd.sjoin(
    ecmwf_cyclone_gdf, adm, how="inner", predicate="intersects"
)
```

```python
# readiness
readiness_storms = ecmwf_cyclones_on_land[
    ((ecmwf_cyclones_on_land["lead_time"] > 72))
    & (ecmwf_cyclones_on_land["speed"] >= (48 * KNOTS2MS))
]["cyclone_name"].unique()
readiness_storms
```

```python
# action
action_storms = ecmwf_cyclones_on_land[
    ((ecmwf_cyclones_on_land["lead_time"] >= 6))
    & (ecmwf_cyclones_on_land["lead_time"] <= 72)
    & (ecmwf_cyclones_on_land["speed"] >= (48 * KNOTS2MS))
]["cyclone_name"].unique()
action_storms
```

```python
# observational
obs_ws_storms = ecmwf_cyclones_on_land_obs[
    ((ecmwf_cyclones_on_land_obs["lead_time"] == 0))
    & (ecmwf_cyclones_on_land_obs["speed"] >= (48 * KNOTS2MS))
]["cyclone_name"].unique()
obs_ws_storms
```

```python
interpolated_ecmwf_data[
    (interpolated_ecmwf_data["cyclone_name"] == "FREDDY")
    & (interpolated_ecmwf_data["speed"] >= 48 * KNOTS2MS)
]
```

```python
# Lists of storm events
df = storm_cerf_file.copy()
df["Readiness"] = [storm in readiness_storms for storm in all_storms]
df["Action"] = [storm in action_storms for storm in all_storms]
df["Observational Wind Speed"] = [
    storm in obs_ws_storms for storm in all_storms
]
df = df[
    [
        "storm",
        "Readiness",
        "Action",
        "Observational Wind Speed",
        "Total Affected",
        "CERF Allocations",
    ]
]

# Sort the DataFrame by 'Total Affected' in descending order
# Round values in 'Total Affected' and 'CERF Allocations' columns
df_sorted = df.sort_values(by="Total Affected", ascending=False)

# Apply styling
styled_df = (
    df_sorted.style.map(
        highlight_true,
        subset=[
            "Readiness",
            "Action",
            # "Observational Rainfall",
            "Observational Wind Speed",
        ],
    )
    .map(color_bar_affected, subset=["Total Affected"])
    .map(color_bar_cerf, subset=["CERF Allocations"])
    .format(
        {
            "Total Affected": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
            "CERF Allocations": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
        }
    )
    .set_table_styles(
        {"": [{"selector": "table", "props": "background-color: white;"}]}
    )
)

# Display the styled DataFrame
styled_df
```

Adding which cyclones would be triggered using La ReUnion

```python
df_rsmc_dist = rsmc.load_historical_forecast_distances()
```

```python
df_rsmc = pd.read_parquet(
    rsmc.DATA_DIR
    / "private"
    / "processed"
    / "moz"
    / "rsmc"
    / "rsmc_forecasts_interp_distances_withradius.parquet"
)
```

```python
# adding buffer
df_rsmc["radius_max_wind_km"] = (
    df_rsmc["radius_max_wind_nm"].astype(float) * KPH2KNOTS
)
```

```python
mf_lr_gdf = gpd.GeoDataFrame(
    df_rsmc,
    geometry=gpd.points_from_xy(df_rsmc.longitude, df_rsmc.latitude),
    crs="EPSG:4326",  # Assuming WGS84
)
mf_lr_gdf.plot()
```

```python
mf_lr_gdf_buffer = mf_lr_gdf.copy()
mf_lr_gdf_buffer["radius_max_wind_km"] = (
    mf_lr_gdf_buffer["radius_max_wind_km"].fillna(0.001).replace(0, 0.001)
)
mf_lr_gdf_buffer["geometry"] = mf_lr_gdf_buffer.geometry.buffer(
    mf_lr_gdf_buffer["radius_max_wind_km"] / KMS2DEGREE
)
mf_lr_gdf_buffer.plot()
```

```python
mf_lr_on_land_adm1 = gpd.sjoin(
    mf_lr_gdf, adm, how="inner", predicate="intersects"
)
mf_lr_on_land_adm2 = gpd.sjoin(
    mf_lr_gdf, adm2_sel, how="inner", predicate="intersects"
)
mf_lr_on_land_adm2_buffer = gpd.sjoin(
    mf_lr_gdf_buffer, adm2_sel, how="inner", predicate="intersects"
)
```

```python
mf_lr_on_land_adm1["name"].unique()  # cyclones that made it to land
```

```python
# readiness
buffer = True
if buffer:
    mf_lr_on_land_adm2_df = mf_lr_on_land_adm2_buffer
else:
    mf_lr_on_land_adm2_df = mf_lr_on_land_adm2
```

```python
# readiness
# Get storms that meet the thresholds
readiness_storms = mf_lr_on_land_adm2_df[
    (mf_lr_on_land_adm2_df["lt_hour"] > 72)
    & (
        (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
        | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
    )
]["name"].unique()
readiness_storms
```

```python
# action
action_storms = mf_lr_on_land_adm2_df[
    ((mf_lr_on_land_adm2_df["lt_hour"] >= 6))
    & (mf_lr_on_land_adm2_df["lt_hour"] <= 72)
    & (
        (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
        | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
        & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
    )
]["name"].unique()
action_storms
```

```python
# observational
obs_ws_storms = mf_lr_on_land_adm1[
    ((mf_lr_on_land_adm1["lt_hour"] < 6))
    & (mf_lr_on_land_adm1["max_wind_kt"] >= (speed_threshold))
]["name"].unique()
obs_ws_storms = np.concatenate((obs_ws_storms, ["CHIDO", "DIKELEDI", "JUDE"]))

obs_ws_storms
```

```python
rain_df = pd.read_csv(
    AA_DATA_DIR
    / "public"
    / "processed"
    / "moz"
    / "daily_imerg_cyclone_landfall_fixed.csv"
)
imerg_data = rain_df[(rain_df["radius"] == 250)]
imerg_df = imerg_data[
    imerg_data["time_step"].isin([-1, 0, 1])
].copy()  # Create a copy to avoid warnings
# Ensure 'date' is in datetime format
imerg_df["date"] = pd.to_datetime(imerg_df["date"], format="%d/%m/%Y %H:%M")
# Create month_year column
imerg_df["year_month"] = imerg_df["date"].dt.to_period("M")
imerg_sum_df = (
    imerg_df.groupby(["storm", "year_month"])["median_precip"]
    .sum()
    .reset_index()
)

obs_rain_storms = imerg_sum_df[imerg_sum_df["median_precip"] >= 55][
    "storm"
].unique()
# rename IDAI 1 to IDAI
obs_rain_storms[obs_rain_storms == "IDAI 1"] = "IDAI"
obs_rain_storms = np.concatenate((obs_rain_storms, ["JUDE", "DIKELEDI"]))
obs_rain_storms
```

```python
# Lists of storm events
df["Readiness"] = [storm in readiness_storms for storm in all_storms]
df["Action"] = [storm in action_storms for storm in all_storms]
df["Observational Wind Speed"] = [
    storm in obs_ws_storms for storm in all_storms
]
df["Observational Rainfall"] = [
    storm in obs_rain_storms for storm in all_storms
]
df = df[
    [
        "storm",
        "Readiness",
        "Action",
        "Observational Wind Speed",
        "Observational Rainfall",
        "Total Affected",
        "CERF Allocations",
    ]
]

# Sort the DataFrame by 'Total Affected' in descending order
# Round values in 'Total Affected' and 'CERF Allocations' columns
df_sorted = df.sort_values(by="Total Affected", ascending=False)

# Apply styling
styled_df = (
    df_sorted.style.map(
        highlight_true,
        subset=[
            "Readiness",
            "Action",
            "Observational Wind Speed",
            "Observational Rainfall",
        ],
    )
    .map(color_bar_affected, subset=["Total Affected"])
    .map(color_bar_cerf, subset=["CERF Allocations"])
    .format(
        {
            "Total Affected": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
            "CERF Allocations": lambda x: (
                f"{int(x):,}" if pd.notna(x) else ""
            ),  # Format with commas, no decimals, NaN as blank
        }
    )
    .set_table_styles(
        {"": [{"selector": "table", "props": "background-color: white;"}]}
    )
)

# Display the styled DataFrame
styled_df
```

```python
# checking which months and years each trigger would have been met
# readiness
readiness_trigger_years = (
    mf_lr_on_land_adm2_df[
        ((mf_lr_on_land_adm2_df["lt_hour"] > 72))
        & (
            (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
            | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
        )
    ]["valid_time"]
    .dt.tz_localize(None)  # Remove timezone information
    .dt.to_period("M")
    .unique()
)
readiness_trigger_years
```

```python
# action
action_trigger_years = (
    mf_lr_on_land_adm2_df[
        ((mf_lr_on_land_adm2_df["lt_hour"] >= 6))
        & (mf_lr_on_land_adm2_df["lt_hour"] <= 72)
        & (
            (mf_lr_on_land_adm2_df["max_wind_kt"] >= 48)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_48))
            | (mf_lr_on_land_adm2_df["max_wind_kt"] >= 64)
            & (mf_lr_on_land_adm2_df["ADM2_PT"].isin(ADM2_64))
        )
    ]["valid_time"]
    .dt.tz_localize(None)  # Remove timezone information
    .dt.to_period("M")
    .unique()
)
action_trigger_years
```

```python
# observational
obs_ws_trigger_years = (
    mf_lr_on_land_adm1[
        ((mf_lr_on_land_adm1["lt_hour"] == 0))
        & (mf_lr_on_land_adm1["max_wind_kt"] >= (48))
    ]["valid_time"]
    .dt.tz_localize(None)  # Remove timezone information
    .dt.to_period("M")
    .unique()
)
obs_ws_trigger_years
```

```python
obs_rain_trigger_years = imerg_sum_df[imerg_sum_df["median_precip"] >= 55][
    "year_month"
].unique()
obs_rain_trigger_years
```

```python
min_year_windspeed = "2010-10"
min_year_rainfall = "2003-03"
max_year_rainfall = ""
```

```python
historical_activations = pd.DataFrame(
    {"year_month": pd.period_range(start="2000-01", end="2024-06", freq="M")}
)
historical_activations["readiness"] = historical_activations[
    "year_month"
].isin(readiness_trigger_years)
historical_activations["action"] = historical_activations["year_month"].isin(
    action_trigger_years
)
historical_activations["observational_windspeed"] = historical_activations[
    "year_month"
].isin(obs_ws_trigger_years)
historical_activations["observational_rainfall"] = historical_activations[
    "year_month"
].isin(obs_rain_trigger_years)
# Apply the date constraints
historical_activations.loc[
    historical_activations["year_month"]
    < pd.Period(min_year_windspeed, freq="M"),
    ["readiness", "action", "observational_windspeed"],
] = np.nan
historical_activations.loc[
    historical_activations["year_month"]
    < pd.Period(min_year_rainfall, freq="M"),
    "observational_rainfall",
] = np.nan

historical_activations
```

```python
historical_activations.to_csv(
    rsmc.DATA_DIR / "public/processed/moz/historical_activations.csv",
    index=False,
)
```
